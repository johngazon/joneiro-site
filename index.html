<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Курс ComfyUI — Заглавная</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Floating profile overlay -->
  <div class="profile-floating">
    <!-- Use a relative path without the images/ prefix because the profile
         picture lives at the project root on GitHub. Removing the extra
         directory prevents broken image links when the site is deployed. -->
    <img src="profile.jpg" alt="Джон Крылов">
    <div class="profile-info">
      <p class="profile-name">Джон Крылов</p>
      <p class="profile-role">Режиссёр монтажа, моушн дизайнер</p>
      <a href="https://t.me/Joneuro" class="profile-link">@Joneuro</a>
    </div>
  </div>

  <main>
    <section class="nodes">
    <!-- Page title node -->
    <div class="node accent-blue">
      <h1>Как подключить ComfyUI к рабочему процессу и получить +15 свободных часов в неделю — с готовым сценарием и без технического бэкграунда.</h1>
    </div>

    <!-- Photo gallery node: a scrollable strip of recent photos -->
    <div class="node accent-orange gallery-node">
      <div class="gallery-carousel">
        <div class="gallery-track">
          <img src="images/gallery/photo_2024-03-14_17-14-06.jpg" alt="Photo 1">
          <img src="images/gallery/photo_2024-03-14_17-14-07.jpg" alt="Photo 2">
          <img src="images/gallery/photo_2024-03-26_18-29-55.jpg" alt="Photo 3">
          <img src="images/gallery/photo_2024-04-04_12-58-24.jpg" alt="Photo 4">
          <img src="images/gallery/photo_2024-04-08_15-27-59.jpg" alt="Photo 5">
          <img src="images/gallery/photo_2025-01-22_19-31-26.jpg" alt="Photo 6">
          <img src="images/gallery/photo_2025-01-22_19-31-27.jpg" alt="Photo 7">
          <img src="images/gallery/photo_2025-01-23_22-14-19.jpg" alt="Photo 8">
          <img src="images/gallery/photo_2025-01-24_18-48-39.jpg" alt="Photo 9">
          <img src="images/gallery/photo_2025-01-25_15-49-19 (2).jpg" alt="Photo 10">
          <img src="images/gallery/photo_2025-01-25_15-49-19.jpg" alt="Photo 11">
          <img src="images/gallery/photo_2025-01-27_00-21-07 (2).jpg" alt="Photo 12">
          <img src="images/gallery/photo_2025-01-27_00-21-07.jpg" alt="Photo 13">
        </div>
        <div class="gallery-dots"></div>
      </div>
    </div>

    <!-- Introduction node -->
    <div class="node accent-pink">
      <h2>Почему это отличается от всего, что вы видели до этого момента</h2>
      <p>Обычно дизайнеру советуют: «Хочешь работать быстрее — прокачай тайм‑менеджмент, установи трекер задач, автоматизируй процессы». Звучит разумно, но на деле почти не помогает. Потому что дело не во времени, а в том, что сами задачи перегружены рутиной.</p>
      <p>Я предложил другой путь — подключить ComfyUI так, чтобы она реально помогала. Например, мы автоматизировали вырезание объектов с фона, генерацию разных вариантов дизайна и быстрые ресайзы. Всё работает просто: один раз настраивается — и потом экономит по несколько часов в день.</p>
    </div>

    <!-- Why implement node -->
    <div class="node accent-green">
      <h2>Почему это нужно внедрять сейчас</h2>
      <p>Мы протестировали метод на команде: 4 дизайнера, 3 визуальных ассистента и 2 специалиста из агентств. Уже на 5‑й день работы они стали закрывать задачи на 2–3 часа раньше.</p>
      <p>Например, раньше дизайнер делал баннер с адаптациями под соцсети около трёх часов. С моим сценарием в ComfyUI — всего 40 минут. Программа сама вырезает фон, создаёт стилизованные версии, меняет размер под нужный формат. И всё это — без потери качества.</p>
    </div>

    <!-- What includes node -->
    <div class="node accent-orange">
      <h2>Что именно входит в этот метод</h2>
      <p>Метод — это не просто «включи нейросеть и жди результата». Всё построено по понятной схеме:</p>
      <ul>
        <li>Дизайнер открывает готовый workflow в ComfyUI.</li>
        <li>Загружает свой бриф или референсы.</li>
        <li>Выбирает нужную модель: например, SDXL для генерации фонов или Kontext для точечного редактирования.</li>
        <li>Нажимает старт — и получает не сырую картинку, а рабочий результат, который сразу можно адаптировать под задачу.</li>
      </ul>
      <p>Например, Kontext даёт возможность менять отдельные детали (освещение, цвет глаз, эмоции, одежду) на фото без искажений окружающих пикселей. Это особенно полезно в нейрофотосессиях — можно сгенерировать портреты для презентации, сайта или соцсетей без фотографа и студии, но с живым, естественным результатом.</p>
    </div>

    <!-- Credibility node -->
    <div class="node accent-blue">
      <h2>Почему этому можно верить</h2>
      <p>Никто из ребят не был технарём. Все — обычные дизайнеры, которые раньше даже не открывали ComfyUI. Но результат они получили уже в первую неделю.</p>
      <p>Им не пришлось учиться неделями — я просто дал им готовую пошаговую инструкцию, где всё разложено по полочкам. Они загружали файл, нажимали нужные кнопки — и всё работало. Без сложных настроек и путаницы.</p>
      <p>Если вы думаете:</p>
      <ul>
        <li>«Я не разбираюсь в таких программах»</li>
        <li>«Я пробовал раньше, ничего не понял»</li>
        <li>«Мне лень во всё это вникать»</li>
      </ul>
      <p>Понимаю. Но как раз в этом методе никто не просит вас вникать глубоко. Я специально упростил всё, насколько возможно: настроил интерфейс, сделал его понятным, заранее подключил нужные инструменты. Вам нужно просто следовать шагам, как в инструкции по сборке конструктора.</p>
    </div>

    <!-- Results node -->
    <div class="node accent-pink">
      <h2>Кто уже получил результат</h2>
      <p>После эксперимента ребята начали считать время. Один дизайнер, который раньше заканчивал в 8 вечера, теперь освобождается к 5. У другого освободилось утро.</p>
      <p>Одна визуалка из агентства сказала, что впервые за месяц смогла просто выйти на прогулку — и не думать о правках. Все стали меньше уставать. Потому что рутинные задачи теперь делаются автоматически — руками почти ничего не приходится доделывать.</p>
    </div>

    <!-- About author node -->
    <div class="node accent-green">
      <h2>Почему меня стоит слушать</h2>
      <p>Меня зовут Джон Крылов. Сейчас я старший режиссёр монтажа в МИА «Россия сегодня», работаю на проектах РИА «Новости» и «Спутник». До этого я был на Первом канале — и там же, ещё несколько лет назад, я впервые начал использовать нейросети в своей работе.</p>
      <p>Один из первых серьёзных кейсов был связан с восстановлением старых портретных фотографий: изображения 512×512 были плохого качества, и я начал использовать апскейлеры на базе Stable Diffusion, как раз через ComfyUI. Это дало отличный результат, и я быстро подключил к этому весь отдел. Мы начали регулярно улучшать исходники с помощью нейросетей прямо в производственном цикле.</p>
      <p>Позже, уже в «Россия сегодня», мы масштабировали этот подход на весь холдинг. Все редакции начали использовать нейросети: сначала — для создания аватаров через сторонние сервисы, а затем — именно ComfyUI для более сложных задач. С его помощью мы делали:</p>
      <ul>
        <li>Раскадровки для видеосъёмок и анимации: художник создаёт скетч — нейросеть превращает его в полноценный кадр.</li>
        <li>Нейрофотосессии с обучением LoRA‑моделей: мы обучали модели на фото политиков и других публичных персон, чтобы быстро генерировать изображения в нужном стиле и на нужном фоне (например, с государственным флагом).</li>
        <li>Кастомные визуальные материалы под новостные задачи, без необходимости в фотобанках или съёмках.</li>
      </ul>
      <p>Я изучаю эту технологию уже больше четырёх лет. Начинал ещё с автоматических скриптов на ранних версиях Stable Diffusion, потом перешёл на ComfyUI — и был рад, что появился инструмент с гибкой логикой на нодах, где всё можно собрать под себя.</p>
      <p>Почему меня стоит слушать? Потому что я не теоретик. Всё, о чём я рассказываю — это опыт, проверенный в реальной работе с большими редакциями, с жёсткими дедлайнами и высокими требованиями к качеству. И я не просто научился использовать ComfyUI сам — я внедрил его в реальную индустрию, адаптировал под процессы и обучил других. Я знаю, какие проблемы возникают вначале — и как их решать, чтобы сэкономить ваше время и нервы.</p>
    </div>
    </section>

    <!-- Footer links and buttons -->
    <div class="footer-links">
      <a class="link" href="page2.html">УЗНАТЬ ОБ УНИКАЛЬНОМ МЕТОДЕ</a>
    </div>
  </main>

  <!-- Animated floating particles -->
  <div class="flares">
    <span></span><span></span><span></span><span></span><span></span>
    <span></span><span></span><span></span><span></span><span></span>
  </div>

  <!-- SVG connectors between nodes -->
  <svg class="connectors" xmlns="http://www.w3.org/2000/svg"></svg>

  <!-- Floating call-to-action buttons. Always visible on screen -->
  <div class="cta-fixed">
    <!-- Primary purchase button. Does not navigate yet -->
    <a class="btn btn-buy" href="#">Купить</a>
    <!-- Course details button -->
    <a class="btn btn-course" href="page3.html">Подробнее о курсе</a>
    <!-- Unique method link button -->
    <a class="btn btn-method" href="page2.html">Узнать об уникальном методе</a>
  </div>

  <!-- Script for drawing connectors on scroll/resize -->
  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const nodes = Array.from(document.querySelectorAll('.node'));
      const svg = document.querySelector('.connectors');
      // Colour mapping based on accent classes for ports and connectors
      const colourMap = {
        'accent-blue': 'rgba(33, 203, 243, 0.6)',
        'accent-pink': 'rgba(233, 30, 99, 0.6)',
        'accent-green': 'rgba(76, 175, 80, 0.6)',
        'accent-orange': 'rgba(255, 152, 0, 0.6)'
      };
      // Create input/output ports for each node and apply colour coding
      nodes.forEach(node => {
        const inputPort = document.createElement('div');
        inputPort.classList.add('input-port');
        const outputPort = document.createElement('div');
        outputPort.classList.add('output-port');
        // Determine port colour based on accent class
        let portColour = 'rgba(33, 203, 243, 1)';
        node.classList.forEach(cls => {
          if (colourMap[cls]) {
            // convert semi‑transparent colour to fully opaque for ports
            const rgb = colourMap[cls].replace(/rgba\(([^,]+), ([^,]+), ([^,]+), [^)]+\)/, '$1,$2,$3');
            portColour = `rgb(${rgb})`;
          }
        });
        inputPort.style.backgroundColor = portColour;
        inputPort.style.borderColor = portColour;
        outputPort.style.backgroundColor = portColour;
        outputPort.style.borderColor = portColour;
        node.appendChild(inputPort);
        node.appendChild(outputPort);
      });
      // Disable the parallax effect on scroll. Previously each node was
      // translated horizontally based on scroll position. To create a more
      // stable reading experience we simply reset any inline transforms on
      // nodes. This function is still called on scroll to keep API
      // compatibility with the rest of the script.
      function updateParallax() {
        nodes.forEach(node => {
          node.style.transform = '';
        });
      }
      function updateConnectors() {
        // Adjust svg dimensions to cover the full document height
        const docHeight = document.body.scrollHeight;
        svg.setAttribute('height', docHeight);
        svg.setAttribute('width', document.documentElement.clientWidth);
        // Clear existing connectors
        while (svg.firstChild) {
          svg.removeChild(svg.firstChild);
        }
        nodes.forEach((node, idx) => {
          // Connect each node to the next; choose orientation based on index
          const next = nodes[idx + 1];
          if (!next) return;
          // Alternate orientation: even indexes connect right‑to‑right, odd indexes left‑to‑left
          const orientation = idx % 2 === 0 ? 'right' : 'left';
          // Choose ports based on orientation
          const startPort = orientation === 'right' ? node.querySelector('.output-port') : node.querySelector('.input-port');
          const endPort = orientation === 'right' ? next.querySelector('.output-port') : next.querySelector('.input-port');
          if (!startPort || !endPort) return;
          const rect1 = startPort.getBoundingClientRect();
          const rect2 = endPort.getBoundingClientRect();
          // Starting and ending coordinates: anchor to the appropriate side
          let startX, endX;
          if (orientation === 'right') {
            startX = rect1.left + rect1.width + window.scrollX;
            endX = rect2.left + rect2.width + window.scrollX;
          } else {
            startX = rect1.left + window.scrollX;
            endX = rect2.left + window.scrollX;
          }
          const startY = rect1.top + rect1.height / 2 + window.scrollY;
          const endY = rect2.top + rect2.height / 2 + window.scrollY;
          // Offset controls horizontally based on vertical distance to create nice arcs
          const verticalDistance = Math.abs(endY - startY);
          const baseOffset = Math.max(100, verticalDistance * 0.6);
          const offset = orientation === 'right' ? baseOffset : -baseOffset;
          const ctrl1X = startX + offset;
          const ctrl1Y = startY;
          const ctrl2X = endX + offset;
          const ctrl2Y = endY;
          const pathData = `M ${startX},${startY} C ${ctrl1X},${ctrl1Y} ${ctrl2X},${ctrl2Y} ${endX},${endY}`;
          const path = document.createElementNS('http://www.w3.org/2000/svg', 'path');
          path.setAttribute('d', pathData);
          // Determine colour based on the accent class of the current node
          let strokeColour = 'rgba(0, 200, 180, 0.6)';
          node.classList.forEach(cls => {
            if (colourMap[cls]) {
              strokeColour = colourMap[cls];
            }
          });
          path.setAttribute('stroke', strokeColour);
          path.setAttribute('stroke-width', '2');
          path.setAttribute('fill', 'none');
          path.setAttribute('stroke-linecap', 'round');
          path.setAttribute('stroke-dasharray', '6 6');
          path.style.animation = 'dash-motion 4s linear infinite';
          svg.appendChild(path);
        });
      }
      function onScroll() {
        updateParallax();
        updateConnectors();
      }
      // Initial draw
      updateParallax();
      updateConnectors();
      window.addEventListener('resize', updateConnectors);
      window.addEventListener('scroll', onScroll);

      // Build an interactive slider for the photo gallery.
      // The gallery displays one image at a time, supports swipe gestures,
      // auto‑advances every few seconds, and shows dots for navigation.
      const track = document.querySelector('.gallery-track');
      const slides = track ? Array.from(track.children) : [];
      const dotsContainer = document.querySelector('.gallery-dots');
      let currentSlide = 0;
      let autoSlideTimer;

      function createDots() {
        if (!dotsContainer) return;
        dotsContainer.innerHTML = '';
        slides.forEach((slide, index) => {
          const dot = document.createElement('span');
          dot.addEventListener('click', () => {
            currentSlide = index;
            updateGallery();
            resetAutoSlide();
          });
          dotsContainer.appendChild(dot);
        });
      }

      function updateGallery() {
        if (!track || slides.length === 0) return;
        const slideWidth = track.getBoundingClientRect().width / slides.length;
        track.style.transform = `translateX(-${currentSlide * slideWidth}px)`;
        if (dotsContainer) {
          const dots = Array.from(dotsContainer.children);
          dots.forEach((dot, idx) => {
            dot.classList.toggle('active', idx === currentSlide);
          });
        }
      }

      function nextSlide() {
        if (slides.length === 0) return;
        currentSlide = (currentSlide + 1) % slides.length;
        updateGallery();
      }

      function startAutoSlide() {
        clearInterval(autoSlideTimer);
        autoSlideTimer = setInterval(nextSlide, 5000);
      }

      function resetAutoSlide() {
        clearInterval(autoSlideTimer);
        autoSlideTimer = setTimeout(startAutoSlide, 5000);
      }

      if (track) {
        // Set up widths so that each slide fills the gallery viewport.
        track.style.width = `${slides.length * 100}%`;
        slides.forEach(slide => {
          slide.style.width = `${100 / slides.length}%`;
        });
        createDots();
        updateGallery();
        startAutoSlide();
        // Swipe handling
        let startX = 0;
        let isDragging = false;
        let deltaX = 0;
        track.addEventListener('pointerdown', (e) => {
          startX = e.clientX;
          isDragging = true;
          track.style.transition = 'none';
          clearInterval(autoSlideTimer);
        });
        track.addEventListener('pointermove', (e) => {
          if (!isDragging) return;
          deltaX = e.clientX - startX;
          const slideWidth = track.getBoundingClientRect().width / slides.length;
          track.style.transform = `translateX(${ -currentSlide * slideWidth + deltaX }px)`;
        });
        function endDrag() {
          if (!isDragging) return;
          const slideWidth = track.getBoundingClientRect().width / slides.length;
          // Snap to next or previous slide if dragged enough
          if (Math.abs(deltaX) > slideWidth / 4) {
            if (deltaX < 0 && currentSlide < slides.length - 1) {
              currentSlide++;
            } else if (deltaX > 0 && currentSlide > 0) {
              currentSlide--;
            }
          }
          track.style.transition = 'transform 0.6s ease';
          updateGallery();
          startAutoSlide();
          isDragging = false;
          deltaX = 0;
        }
        track.addEventListener('pointerup', endDrag);
        track.addEventListener('pointerleave', endDrag);
      }
    });
  </script>
</body>
</html>